\section{Discussion}
% \quickwordcount{03.6_discussion}

In this work, we introduced SpinWalk, a Monte Carlo simulator mainly designed for BOLD fMRI applications, but not limited to this application. SpinWalk is a free and open-source software (FOSS) that utilizes either GPU or CPU acceleration, depending on the user's preference, and can simulate signals of custom MR sequences. It has minimal dependencies, all of which are open source and available for a wide range of hardware architectures and platforms. The capabilities and performance of SpinWalk were exemplarily demonstrated by simulating various sequences in different scenarios and successfully replicating results from previous studies.

To evaluate BOLD signal change across different vessel sizes, the simulations in this work employed a FoV scaling approach. This method allows for the simulation of a wide range of vessel sizes without the need to create numerous numerical phantoms. FoV scaling ensures a constant BVF across simulations and maintains consistent cylinder placement, leading to more uniform simulations. However, careful selection of the original unscaled phantom is crucial, taking into account the range of downscaling and upscaling, as well as the ratio of vessel size to FoV and grid size in the original unscaled phantom. The results obtained from the FoV scaling analysis (see Results section) for very small and large cylinder radii prompted a deeper investigation into the factors that may influence stability and accuracy. This additional analysis aimed to identify and understand the variables that significantly impact the reliability of the simulations. These limitations were characterized and described in detail. It is also important to note that the FoV will not remain identical for different vessel sizes after scaling. Conversely, placing a large vessel within a small FoV while maintaining a small BVF can be challenging, making FoV scaling particularly useful in such cases. This approach of course is limited to the case of spatially isotropic cylinders as already mentioned. In case of more sophisticated models that for instance mimic pial and penetrating vessels, there is most likely not much sense in scaling the entire model.


\subsection{Further Performance Improvements}

One aim in developing SpinWalk was to reduce the runtime of simulating steady-state MR sequences like bSSFP. SpinWalk now enables such simulations to be completed in just a few minutes rather than in several hours, not only for analytically described vascular architectures but also for arbitrary geometries. However, profiling analysis and insights from related literature reveal that there is still potential for performance improvement. Notably, generating random numbers for the random walk and memory bandwidth were identified as performance bottlenecks. It has been noted that the time needed to transfer data between RAM and DRAM in numerous simulations is often as long as, or even longer than, the time required for the simulation process itself. Furthermore, each 3D random walk involves three random number generations, and additional random walks may be required if the simulated trajectory exits the region defined by the substrate (impermeability) or the restricted environment (FoV). 

To address these issues, random walks can be conducted in polar coordinates with fixed step sizes, reducing random number generation to just two per time step (\cite{rafael2020robust, lee2021realistic}). Alternatively, random walks can be further optimized by using precomputed look-up tables for azimuthal and polar angles, reducing random number generation to only one per time step (\cite{Sandgaard2024Towards}). As shown in Figure \ref{fig:benchmark}, increasing voxel mesh resolution leads to slower calculations due to limited memory bandwidth, which must support the demands of thousands of CUDA cores simultaneously. In contrast, CPU calculations are less affected by this issue because they involve a lower degree of parallelism. Many Monte Carlo simulators use triangular meshes as input to define substrate surfaces, which are relatively memory-efficient and helpful here but can be computationally intensive (\cite{Riedmatten2024Flexible}). CACTUS (\cite{villarreal2023cactus}) and ConFiG (\cite{callaghan2020config}) utilize triangulated meshes to represent substrate geometry, which can be computationally demanding. In contrast, MEDUSA (\cite{ginsburger2019medusa}) breaks down each microstructural element into a set of overlapping spheres, offering greater efficiency in terms of both memory usage and computational requirements. However, it is important to consider how to deal with off-resonance effects in 3D space when using such meshes. To calculate the field inhomogeneity in complex geometries, the finite perturber method is preferred for its simplicity of implementation (\cite{pathak2008novel}), which requires a voxel representation of the substrates. Voxelization methods, such as the signed distance function or ray-casting base (\cite{roth1982ray, winther2024susceptibility}) method, can be utilized to convert surface mesh representations — like those produced by CACTUS and ConFiG — into a voxel representation.

There is a trade-off between computational performance and the versatility of the simulator. For narrowly defined targets with specific assumptions, performance can be highly optimized, as demonstrated with simDRIFT. In contrast, SpinWalk accounts for a range of factors, including off-resonance effects, relaxation, and permeability, and allows for a variable number of RF pulses and gradients. This flexibility enables the simulation of numerous sequences and evaluate a wide array of parameters.


\subsection{Limitations and Exclusions}

Most numerical simulations typically depend on several assumptions regarding tissue models and pulse sequences. SpinWalk follows some of this approach to achieve performance gains too. In each time step, sequence components are applied sequentially: first, a random walk is performed; then ideal dephasing is applied, followed by the application of gradients, RF pulses, and finally, the recording of the echo and trajectory. Thus, RF and gradients are not applied simultaneously.

In the simulation of permeability, spins exiting the substrate are not compensated. This must be carefully considered when analyzing long-duration sequences, as no spins may remain within the substrate (e.g., in intravascular space). This bias is particularly relevant for simulations conducted over relatively long durations. This phenomenon is observed in the bSSFP sequence results depicted in Figure \ref{fig:permeability}. To prevent a reduction in SNR, it is crucial to maintain a constant average spin density. If spin density is not preserved, the effect may be further amplified in cases of varying diffusivity between two adjacent permeable substrates, where spins tend to accumulate in regions with lower diffusivity (Figure \ref{fig:diffusion_bias}), potentially introducing bias into simulations (\cite{fieremans2018physical}). This bias is typically negligible in short-duration simulations like GRE and SE but can be significant in bSSFP. In the simulations presented in this study, both intravascular and extravascular regions were modeled with identical diffusivity. In in vivo experiments, fresh spins introduced by flow are expected, leading to increased signal changes in bSSFP, particularly in small vessels. Addressing constant permeability and maintaining spin density are potential areas for improving the simulations.

While SpinWalk can generate numerical phantoms filled with cylinders or spheres for demonstration of simple models, it is not capable of generating vascular anatomical network (VAN) or realistic cell models. These models, as well as the resulting off-resonance maps, need to be generated separately and fed to SpinWalk, as the primary aim of the SpinWalk is to facilitate versatile sequence simulation while being high performance.

Phantoms with voxel mesh representation are relatively large. One should consider the DRAM capacity of their GPU, as the entire phantom data will be copied there. Nowadays, many modern GPUs are equipped with at least 16GB of DRAM, which should be sufficient for a grid size of 1400 in each dimension. This corresponds to a voxel mesh resolution of 0.5\,µm for a FoV of 700\,µm. For a higher voxel resolution, FoV should be reduced. Theoretically in case limitations are faced at this point, one could consider splitting up the matrix into several sub-matrices that fit the available memory. This would inevitably result in an additional overhead of accessing memory and reduce the performance, but in principle would allow arbitrary matrix sizes to be used.
